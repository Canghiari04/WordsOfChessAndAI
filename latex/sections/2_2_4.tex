La fase di pre-elaborazione dei dati può influenzare in modo significativo l'esito dei risultati di un modello di machine learning. Il preprocessing svolge un ruolo vitale in qualsiasi operazione di classificazione, poichè migliora la qualità delle informazioni disponibili garantendo una maggiore efficacia e accuratezza degli algoritmi di apprendimento automatico impiegati. \vspace{7pt} \\
Poichè il caso di studio utilizza dati provenienti dal \textbf{linguaggio naturale}, la conversione dell'informazioni testuali in un formato idoneo, le quali per definizione sono disordinate e non-strutturate, rappresenta un passaggio critico. \vspace{7pt} \\
Tendenzialmente, affinché sia migliorata la qualità dei testi, sono implementate determinate tecniche dedite alla pre-elaborazione, suddivise in:
\begin{itemize}
    \renewcommand{\labelitemi}{-}
    \item \textbf{Casefolding}. \\ Il casefolding consiste nella trasformazione di una stringa in minuscolo oppure in maiuscolo, in modo tale da ovviare a circostanze in cui sia dettata l'importanza di una parola in base alla sua forma.
    \item \textbf{Lemmatizzazione}. \\ Le parole articolate all'interno di un discorso possiedono flessioni differenti: i sostantivi variano sintatticamente dal plurale al singolare, mentre i predicati differiscono in base alla forma verbale. Un approccio possibile prevede di uniformare ogni termine, ignorandone la coniugazione, convertendo i nomi al singolare e i verbi all'infinito. In sintesi, ogni parola viene convertita nel suo \textbf{lemma}, ovvero nella sua forma originale.
    \item \textbf{RegEx}. \\ Abbreviazione di \textbf{Regular Expression}, \textbf{RegEx} è uno strumento estramemente potente per la costruzione di pattern di ricerca, impiegati per individuare specifiche sezioni di testo. Il suo caso d'uso principe consiste nella rimozione di parti ritenute superflue di un documento.
    \item \textbf{Stopwords}. \\ Sono categorie di parole che si ripetono con una certa insistenza all'interno di una lingua, come ad esempio gli articoli oppure le congiunzioni, le quali possiedono un valore marginale. L'insieme di questi termini è riconosciuto con la denominazione \textbf{stopwords}, spesso rimosse a priori dal testo. Librerie del calibro di \textbf{NLTK} forniscono insiemi di stopwords in base alla lingua indicata, affinchè possano essere eliminate.
\end{itemize}
L'implementazione delle tecniche richiede una previa operazione di \textbf{segmentazione}, in cui il contenuto di un documento viene scomposto in molteplici entità. Un esempio comune consiste nella \textbf{word tokenization}, dove un determinato elemento \textbf{tokenizer} suddivide un testo nella lista di parole che lo compone.