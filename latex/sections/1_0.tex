La \textbf{classificazione testuale} è uno dei classici problemi in ambito \textbf{Natural Language Processing (NLP)}. Lo scopo della tecnica prevede di assegnare ad una collezione di dati una lista di categorie predefinite. \vspace*{7pt} \\
Negli ultimi anni, lo studio relativo alla classificazione testuale ha riscontrato una crescita senza precedenti, causata dalla semplice reperibilità di elevati quantitavi di informazioni. \vspace*{7pt} \\
Nonostante sia estremamente semplice reperire insiemi di dati, solitamente sono riportati in un formato testuale, in gergo denominati \textbf{dati non-strutturati}, impraticabili per eseguire qualsiasi task di \textbf{machine learning}. Pertanto, è necessario adoperare alcune rappresentazioni numeriche, convertendoli in \textbf{dati strutturati}. \vspace*{7pt} \\
La complessità di una classificazione testuale, secondo una lista predefinita di categorie, dipende strettamente dalla natura dell'insieme di dati analizzato, in cui la presenza di \textbf{osservazioni etichettate} detiene un ruolo fondamentale: con l'espressione osservazioni etichettate si intendono dati a cui sono state assegnate delle classi. Qualora il dataset ottenuto contenga informazioni previamente annotate è possibile adeguare modelli di apprendimento automatico di tipo \textbf{supervisionato}. Tuttavia, a causa dell'elevata complessità di ricavare dati già etichettati, spesso sono impiegati algoritmi \textbf{non-supervisionati}, capaci di estrapolare correlazioni tra le differenti entità anche in assenza di categorizzazioni. \vspace*{7pt} \\
Il problema affrontato in questa sede ritrae gli aspetti più ostici descritti fino ad ora, poiché combina dati non-strutturati e l'utilizzo di algoritmi non-supervisionati. Da questa circostanza emerge l'esigenza di delineare le tappe principali affinché da informazioni in linguaggio naturale possano essere adeguate strategie di classificazione. \vspace*{7pt} \\
Il caso di studio di questa tesi nasce da una precedente pubblicazione accademica \cite{Borghesi_2024}, in cui si tenta di estrarre parole chiave e argomenti ricorrenti da un'ampia raccolta di articoli scientifici, relativi all'evoluzione del rapporto tra intelligenza artificiale e computer chess, mediante l'impiego di svariate tecniche di machine learning. Dallo stesso archivio di documenti, è stato realizzato un dataset contenente i domini principali che caratterizzino ciascun paper, focalizzando l'obiettivo dell'analisi al miglioramento del processo di estrazione dei dati, valorizzandone la qualità piuttosto che la quantità. Una volta definito l'insieme di dati, è stata effettuata una classificazione testuale degli articoli, rispetto ad alcune liste predefinite di etichette, adottando e testando differenti modelli di apprendimento automatico.